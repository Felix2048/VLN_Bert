{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mikel/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mikel/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mikel/miniconda3/envs/vilbert-mt/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import json\n",
    "import torch\n",
    "from types import SimpleNamespace\n",
    "from vilbert.vilbert import VILBertActionGrounding, BertConfig\n",
    "from pytorch_transformers.tokenization_bert import BertTokenizer\n",
    "from pytorch_transformers.optimization import AdamW, WarmupLinearSchedule\n",
    "import torch.distributed as dist\n",
    "from VLN_config import config as args\n",
    "import random\n",
    "import pandas as pd\n",
    "from dataLoader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import argparse\n",
    "import glob\n",
    "import pdb\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from faster_rcnn import feature_extractor_new as f_extractor\n",
    "from faster_rcnn.feature_extractor_new import featureExtractor\n",
    "#%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace(adam_epsilon=1e-08, baseline=False, bert_model='bert-base-uncased', best_features=5, clean_train_sets=True, config_file='config/bert_base_6layer_6conect.json', distributed=False, do_lower_case=True, dynamic_attention=False, from_pretrained='save_vilbert_action_grounding/vilberActionGrounding.bin', gradient_accumulation_steps=1, img_weight=1, in_memory=False, learning_rate=0.0001, local_rank=-1, max_temporal_memory_buffer=3, mean_layer=False, num_key_frames=6, num_train_epochs=10.0, num_workers=0, objective=1, predict_feature=False, save_name='', seed=42, split='mteval', start_epoch=0, task_specific_tokens=True, tasks='1', threshold_similarity=0.7, track_temporal_features=True, train_batch_size=4, use_tensorboard=True, visual_target=0, warmup_proportion=0.1, without_coattention=False)\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2020 16:55:38 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/mikel/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    args.bert_model, do_lower_case=args.do_lower_case\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2020 16:55:41 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/mikel/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "07/24/2020 16:55:41 - INFO - vilbert.utils -   loading weights file save_vilbert_action_grounding/vilberActionGrounding.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_vilbert_action_grounding/vilberActionGrounding.bin\n"
     ]
    }
   ],
   "source": [
    "config = BertConfig.from_json_file(args.config_file)\n",
    "bert_weight_name = json.load(\n",
    "    open(\"config/\" + args.bert_model + \"_weight_name.json\", \"r\")\n",
    ")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    args.bert_model, do_lower_case=args.do_lower_case\n",
    ")\n",
    "\n",
    "config.track_temporal_features = args.track_temporal_features\n",
    "config.mean_layer = args.mean_layer\n",
    "config.max_temporal_memory_buffer = args.max_temporal_memory_buffer\n",
    "config.visualization = True\n",
    "\n",
    "#The path of the finetuned ActionGrounding weights\n",
    "args.from_pretrained = \"save_vilbert_action_grounding/vilberActionGrounding.bin\"\n",
    "\n",
    "print(args.from_pretrained)\n",
    "model = VILBertActionGrounding.from_pretrained(\n",
    "    args.from_pretrained, config=config, default_gpu=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "frcnn_model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "data_loader = DataLoader(\"json_data.json\", frcnn_model, save_or_not = False)\n",
    "path = 'DataLoader.pt'\n",
    "data_loaded = data_loader.load_dataloader(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_masked, pos_enc, spatial, image_mask, tokenized_text, masked_text, masked_lm_token, input_mask, segment_ids, co_attention_mask, infos, masked_img_labels  = data_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward the model with one input example\n",
    "pred_t_train, pred_v_train, att_train = model(input_ids = masked_text[1].unsqueeze(0).cpu(),\n",
    "                                image_feat = features_masked[1].unsqueeze(0).cpu(), # Linear(2048*config.max_temporal_memory_buffer, 2048)\n",
    "                                image_loc = spatial[1].unsqueeze(0).cpu(),  #Linear(in_features=5, out_features=1024, bias=True)\n",
    "                                image_pos_input = pos_enc[1].unsqueeze(0).cpu(),   #Linear(7, 2048)/(6, 2048)\n",
    "                                token_type_ids = segment_ids[1].unsqueeze(0).cpu(), \n",
    "                                attention_mask = input_mask[1].unsqueeze(0).cpu(), \n",
    "                                image_attention_mask = image_mask[1].unsqueeze(0).cpu(),\n",
    "                                output_all_attention_masks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 37, 30522])\n",
      "torch.Size([5, 37])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd6a4209c18>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(pred_t_train.shape)\n",
    "print(att_train[0][0][\"attn\"][0,0,:5,:].shape) \n",
    "#Only 7 firts elements because the sentence is 5 + 2 special tokens\n",
    "plt.matshow(att_train[0][0][\"attn\"][0,2,:7,:7].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('vilbert-mt': conda)",
   "language": "python",
   "name": "python361064bitvilbertmtconda7bb1bd3e955c469187a4ae8b5b7d6907"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
